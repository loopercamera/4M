{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "In this Notebook the datasets german descriptions are preprocessed (stemming and lemmatization) for better usage on the LLMs. This code does not handle the error, that there are foreign languages in the germand descriptions.\n",
    "\n",
    "#### Result\n",
    "Consistent data that can be used for further implementation of the NLP.\n",
    "\n",
    "The code was created with the assistance of ChatGPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv\n",
    "df= pd.read_csv(\"data/dataset_descriptions.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_descriptions(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "\n",
    "    # Remove duplicate terms\n",
    "    text = re.sub(r'(\\b\\w+(?: \\(\\w+\\))?\\b)(, \\1)+', r'\\1', text)\n",
    "\n",
    "    # Remove square brackets and their content\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # Remove round brackets and their content\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "\n",
    "    # Replace \"+\" with a space\n",
    "    text = re.sub(r'\\+', ' ', text)\n",
    "\n",
    "    # Replace \"#\" and \"|\" with a space\n",
    "    text = re.sub(r'[#|]', ' ', text)\n",
    "\n",
    "    # Remove excessive hyphens and spaces\n",
    "    text = re.sub(r'-+', ' ', text)\n",
    "\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(r'[,.\\-\\(\\)%’:;!?\\'\"/]', ' ', text)  \n",
    "\n",
    "    # Remove all words containing an underscore\n",
    "    text = re.sub(r'\\b\\w*_\\w*\\b', '', text)\n",
    "\n",
    "    # Remove single standalone letters\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "\n",
    "    # Remove all numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "\n",
    "    # Remove all types of quotation marks and asterisks\n",
    "    text = re.sub(r'[\"„“‚‘«»*]', '', text)\n",
    "\n",
    "    # Remove common stopwords (optional - can be expanded)\n",
    "    stopwords = {\"schweiz\", \"mobil\", \"geo\", \"daten\", \"kanton\", \"verordnung\", \"information\", \"system\"}\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
    "\n",
    "    # Clean up double spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commas\n",
    "df['dataset_description_DE'] = df['dataset_description_DE'].map(lambda x: preprocess_descriptions(str(x)) if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes all duplicate titles\n",
    "df.dropna(subset=['dataset_description_DE']) \\\n",
    "  .drop_duplicates(subset=['dataset_description_DE']) \\\n",
    "  .to_csv(\n",
    "      \"data/dataset_descriptions_preprocessed.txt\",\n",
    "      columns=[\"dataset_description_DE\"],\n",
    "      header=None,\n",
    "      index=False\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
