{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This Notebook takes a model from SBERT and predefined mobility keywords. The wordvectors from the mobility keywords are compared to the wordvectors from the german titles. If the similarity is over 50% the dataset is labelled as mobility-data. \n",
    "\n",
    "#### Result\n",
    "This approach seems to fit pretty good for our purpose. From first sight the results are correct, even that the keywords are defined by ChatGPT and not edited yet. So we will take it from here and build on that to improve it even more. There is still the question of how the wordvectors and similarity can be visualised.\n",
    "\n",
    "The code was created with the assistance of ChatGPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haabs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install libraries (only for Colab):\n",
    "# !pip install sentence-transformers -q\n",
    "# !pip install scikit-learn -q\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load the model (automatically downloaded if not already available locally)\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mobility words pool (read from file)\n",
    "def load_mobility_keywords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        keywords = [line.strip() for line in file if line.strip()]  # Ignore empty lines\n",
    "    return keywords\n",
    "\n",
    "# Load the mobility terms from the file\n",
    "mobility_keywords_file = 'data/mobility_keywords_pool.txt'\n",
    "mobility_keywords = load_mobility_keywords(mobility_keywords_file)\n",
    "\n",
    "# mobility_keywords_pool.txt:\n",
    "# Mobilität\n",
    "# Verkehr\n",
    "# Transport\n",
    "# Fahrt\n",
    "# Auto\n",
    "# Fahrrad\n",
    "# Öffentlicher Nahverkehr\n",
    "# Pendeln\n",
    "# Reisen\n",
    "# Bus\n",
    "# Bahn\n",
    "# Verkehrsmittel\n",
    "# Fahrzeug\n",
    "# Mobilitätskonzept\n",
    "# E-Scooter\n",
    "# Flugzeug\n",
    "# Taxi\n",
    "# Schiff\n",
    "# Mobilitätsplattform\n",
    "# Verkehrsdaten\n",
    "# Verkehrsinfrastruktur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert keywords to vectors\n",
    "keyword_embeddings = model.encode(mobility_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for similarity checking\n",
    "def check_similarity(text, keyword_embeddings, model, threshold=0.5):\n",
    "    text_embedding = model.encode([text])\n",
    "    similarities = cosine_similarity(text_embedding, keyword_embeddings)\n",
    "    max_similarity = np.max(similarities)\n",
    "    return max_similarity >= threshold, max_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis completed. File saved at: data\\analysed_datasets.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to analyze the dataset\n",
    "def analyze_dataset(file_path, keyword_embeddings, model, threshold=0.5):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    # Load the file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if the data was loaded correctly\n",
    "    if df.empty:\n",
    "        raise ValueError(\"The file is empty or was not loaded correctly.\")\n",
    "    \n",
    "    # New columns for analysis results\n",
    "    labels = []\n",
    "    scores = []\n",
    "\n",
    "    for description in df.iloc[:, 0]:  # Iterate over each row of the first column\n",
    "        is_mobility, similarity_score = check_similarity(str(description), keyword_embeddings, model, threshold)\n",
    "        label = 'Mobility Data' if is_mobility else 'Not Mobility Data'\n",
    "        labels.append(label)\n",
    "        scores.append(similarity_score)\n",
    "\n",
    "    # Save the results in new columns\n",
    "    df['Analysis Result'] = labels\n",
    "    df['Similarity Score'] = scores\n",
    "\n",
    "    # Save the updated file in the same folder as the input file\n",
    "    output_file = os.path.join(os.path.dirname(file_path), 'analysed_datasets.csv')\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Analysis completed. File saved at: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# paths\n",
    "input_file_path = 'data/random_lines.txt' \n",
    "\n",
    "# Analyze the file (modify this line with your model & embeddings)\n",
    "output_file_path = analyze_dataset(input_file_path, keyword_embeddings, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
