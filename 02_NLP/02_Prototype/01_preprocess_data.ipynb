{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "In this notebook, the preprocessing of the German titles, descriptions, and keywords of each entry is performed. The cleaned and combined text data will be prepared for further use.\n",
    "\n",
    "#### Improvments to consider\n",
    "- Entries without any valid text are deleted, so currently, only German datasets are retained.\n",
    "- Applying keyword-extraction might improve the results. This can be tested later.\n",
    "\n",
    "The code was created with the assistance of ChatGPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                      NaN\n",
      "1        ['haushalte', 'kantonzuerich', 'gemeinden', 'b...\n",
      "2                                                      NaN\n",
      "3                                                      NaN\n",
      "4                                                      NaN\n",
      "                               ...                        \n",
      "29074                                                  NaN\n",
      "29075                                                  NaN\n",
      "29076                                                  NaN\n",
      "29077                                                  NaN\n",
      "29078                                                  NaN\n",
      "Name: dataset_keyword_DE, Length: 29079, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haabs\\AppData\\Local\\Temp\\ipykernel_92648\\2190237542.py:7: DtypeWarning: Columns (2,4,6,7,8,9,10,11,12,13,14,16,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(inputdata_file)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "inputdata_file = 'data/merged_dataset_metadata.csv'\n",
    "outputdata_file ='data/01_preprocessed_merged_dataset_metadata.csv'\n",
    "\n",
    "df = pd.read_csv(inputdata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for text preprocessing dataset_title_DE\n",
    "def preprocess_dataset_title_DE(text):\n",
    "    # Remove duplicate terms\n",
    "    text = re.sub(r'(\\b\\w+(?: \\(\\w+\\))?\\b)(, \\1)+', r'\\1', text)\n",
    "    # Remove square brackets and their content\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    # Remove round brackets and their content\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    # Remove all words containing a dot\n",
    "    text = re.sub(r'\\b\\w*\\.\\w*\\b', '', text)\n",
    "    # Remove file formats\n",
    "    text = re.sub(r'\\b\\w+\\.(csv|json|shp|xls|parquet|rdfxml|jsonld|jsonl|dxf|gpkg|turtle)\\b', '', text)\n",
    "    # Replace \"+\" with a space\n",
    "    text = re.sub(r'\\+', ' ', text)\n",
    "    # Replace \"#\" and \"|\" with a space\n",
    "    text = re.sub(r'[#|]', ' ', text)\n",
    "    # Remove excessive hyphens and spaces\n",
    "    text = re.sub(r'[-]+', ' ', text)\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(r'[,.«»‚’°%*:;!?\\'\"/]', '', text)\n",
    "    # Remove all words containing an underscore\n",
    "    text = re.sub(r'\\b\\w*_\\w*\\b', '', text)\n",
    "    # Remove all numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    # Remove single standalone letters\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "    # Clean up double spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra whitespace and convert to lowercase\n",
    "    return text.strip().lower()\n",
    "\n",
    "# Function for text preprocessing dataset_description_DE\n",
    "def preprocess_dataset_description_DE(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    # Remove duplicate terms\n",
    "    text = re.sub(r'(\\b\\w+(?: \\(\\w+\\))?\\b)(, \\1)+', r'\\1', text)\n",
    "    # Remove square brackets and their content\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    # Remove round brackets and their content\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    # Replace \"+\" with a space\n",
    "    text = re.sub(r'\\+', ' ', text)\n",
    "    # Replace \"#\" and \"|\" with a space\n",
    "    text = re.sub(r'[#|]', ' ', text)\n",
    "    # Remove excessive hyphens and spaces\n",
    "    text = re.sub(r'-+', ' ', text)\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(r'[,.\\-\\(\\)%’:;!?\\'\"/]', ' ', text)  \n",
    "    # Remove all words containing an underscore\n",
    "    text = re.sub(r'\\b\\w*_\\w*\\b', '', text)\n",
    "    # Remove single standalone letters\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "    # Remove all numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    # Remove all types of quotation marks and asterisks\n",
    "    text = re.sub(r'[\"„“‚‘«»*]', '', text)\n",
    "    # Clean up double spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra whitespace and convert to lowercase\n",
    "    return text.strip().lower()\n",
    "\n",
    "def preprocess_dataset_keyword_DE(text_list):\n",
    "    # Join the list into a single string separated by spaces\n",
    "    text = ''.join(text_list)\n",
    "    # Remove all specified punctuation (commas, dots, semicolons, etc.)\n",
    "    text = re.sub(r'[.,-;:!\\'?\\[\\]]', '', text)\n",
    "    # Clean up double spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Convert to lowercase and strip extra spaces\n",
    "    return text.strip().lower()\n",
    "\n",
    "def combine_preprocessed_columns(title_DE, description_DE, keyword_DE):\n",
    "    # Convert each input to string because NaN-Values are float\n",
    "    title_DE = str(title_DE) if pd.notna(title_DE) else ''\n",
    "    description_DE = str(description_DE) if pd.notna(description_DE) else ''\n",
    "    keyword_DE = str(keyword_DE) if pd.notna(keyword_DE) else ''\n",
    "    \n",
    "    # Combine the columns with a space separator\n",
    "    combined_columns = ' '.join([title_DE, description_DE, keyword_DE]).strip()\n",
    "    return combined_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries deleted: 5462\n"
     ]
    }
   ],
   "source": [
    "# preprocess title, description and keyword DE:\n",
    "df['dataset_title_DE_preprocessed'] = df['dataset_title_DE'].map(lambda x: preprocess_dataset_title_DE(str(x)) if pd.notna(x) else x)\n",
    "df['dataset_description_DE_preprocessed'] = df['dataset_description_DE'].map(lambda x: preprocess_dataset_description_DE(str(x)) if pd.notna(x) else x)\n",
    "df['dataset_keyword_DE_preprocessed'] = df['dataset_keyword_DE'].map(lambda x: preprocess_dataset_keyword_DE(str(x)) if pd.notna(x) else x)\n",
    "\n",
    "# Combine the three columns into a new column 'Combined'\n",
    "df['dataset_combined_title_description_keyword_preprocessed'] = df.apply(\n",
    "    lambda row: combine_preprocessed_columns(\n",
    "        row['dataset_title_DE_preprocessed'], \n",
    "        row['dataset_description_DE_preprocessed'], \n",
    "        row['dataset_keyword_DE_preprocessed']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Drop rows where the combined column is empty or only contains whitespace\n",
    "# !!! This Step should not be neccessary later !!!\n",
    "original_row_count = len(df)\n",
    "df = df[df['dataset_combined_title_description_keyword_preprocessed'].str.strip() != '']\n",
    "new_row_count = len(df)\n",
    "deleted_rows = original_row_count - new_row_count\n",
    "print(f\"Number of entries deleted: {deleted_rows}\")\n",
    "\n",
    "# drop the not used columns that are newly created!\n",
    "df.drop(['dataset_title_DE_preprocessed', \n",
    "         'dataset_description_DE_preprocessed', \n",
    "         'dataset_keyword_DE_preprocessed'], axis=1, inplace=True)\n",
    "\n",
    "# create column for labelling\n",
    "df['mobility_dataset'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Datei wurde erfolgreich als data/01_preprocessed_merged_dataset_metadata.csv gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# Write dataframe in new csv-File\n",
    "df.to_csv(outputdata_file, index=False)\n",
    "\n",
    "print(f'Die Datei wurde erfolgreich als {outputdata_file} gespeichert.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
