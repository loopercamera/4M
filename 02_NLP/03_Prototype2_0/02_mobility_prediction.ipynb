{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1f3115",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook processes all labeled entries by passing them through a prompt to the large language model (LLM) Google Gemini. It handles the data in batches of 10 rows from the DataFrame and waits for the result after each batch.\n",
    "\n",
    "#### Improvments to consider\n",
    "- Create multiple API keys to allow more requests per minute and per day.\n",
    "- The prompt is somewhat unstable, as multiple entries are processed in a single request. Processing one entry at a time with max_output_tokens = 1 would be much more stable.\n",
    "- Define promps in other languages\n",
    "\n",
    "The code was created with the assistance of ChatGPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "\n",
    "inputdata_file = 'data/01_labelled_data.csv'\n",
    "outputdata_file ='data/02_predicted_data.csv'\n",
    "\n",
    "with open(\"data/apikeys.json\") as f:\n",
    "    config = json.load(f)\n",
    "API_KEY = config[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a551bf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labelled rows after filtering: 21\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(inputdata_file, dtype={'mobilitydata_labelled': 'string'}, low_memory=False)\n",
    "\n",
    "# Drop rows where 'mobilitydata_labelled' is empty (NaN)\n",
    "df = df.dropna(subset=['mobilitydata_labelled'])\n",
    "\n",
    "# Convert 'mobilitydata_labelled' to boolean type\n",
    "df['mobilitydata_labelled'] = df['mobilitydata_labelled'].map({'True': True, 'False': False})\n",
    "\n",
    "# Print the number of rows remaining after filtering\n",
    "print(f\"Number of labelled rows after filtering: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "# Prepare a new column with empty values to store the results\n",
    "df['mobilitydata_generated'] = None\n",
    "\n",
    "# Iterate over the DataFrame in chunks\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    # Select the relevant columns from the current chunk\n",
    "    chunk_df = df.iloc[i:i + chunk_size][['dataset_title_DE', 'dataset_description_DE']]\n",
    "\n",
    "    # Combine title and description for each entry into a single string\n",
    "    chunk_lines = chunk_df.apply(\n",
    "        lambda row: f\"Titel: {row['dataset_title_DE']}\\nBeschreibung: {row['dataset_description_DE']}\",\n",
    "        axis=1\n",
    "    ).tolist()\n",
    "\n",
    "    # Construct the prompt with all entries in the chunk\n",
    "    prompt = \"Handelt es sich bei folgendem Inhalt um Verkehrs- oder Mobilit√§tsdaten? Antworte nur mit T (True) oder F (False) Zeilenweise.\\n\\n\" + \"\\n\\n\".join(chunk_lines)\n",
    "\n",
    "    # Send the prompt to the Gemini model\n",
    "    response = client.models.generate_content_stream(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[prompt],\n",
    "        config=types.GenerateContentConfig(\n",
    "            max_output_tokens=chunk_size * 2,\n",
    "            temperature=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Collect the response text from the stream\n",
    "    result_text = \"\"\n",
    "    for chunk in response:\n",
    "        result_text += chunk.text\n",
    "\n",
    "    # Split the result into individual predictions\n",
    "    predictions = result_text.strip().splitlines()\n",
    "\n",
    "    # Write the predictions back into the corresponding rows in the DataFrame\n",
    "    target_indices = df.iloc[i:i + len(predictions)].index\n",
    "    df.loc[target_indices, 'mobilitydata_generated'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2793e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been successfully saved as data/02_predicted_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Write dataframe in new csv-File\n",
    "df.to_csv(outputdata_file, index=False)\n",
    "\n",
    "print(f'The file has been successfully saved as {outputdata_file}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
